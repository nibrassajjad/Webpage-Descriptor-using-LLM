{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4847715f-312a-4e7a-b662-b356794a4ce8",
   "metadata": {},
   "source": [
    "# LLM Project: Webpage Descriptor using Llama 3.2\n",
    "\n",
    "This program fetches content of a webpage via user-input and then will output the title of the webpage as well as a small summary of the page with the help of a LLM Model (Llama 3.2).\n",
    "\n",
    "## Step 1: Install Required Libraries\n",
    "To begin, we need the following Python libraries:\n",
    "- `requests`: To fetch the webpage content.\n",
    "- `beautifulsoup4`: To parse and clean up the webpage HTML.\n",
    "- `ollama`: To interface with the locally installed Llama 3.2 model.\n",
    "\n",
    "Once the libraries has been installed in your environment, open up a Jupyter notebook and proceed to next steps.\n",
    "\n",
    "## Step 2: Fetch Webpage Content\n",
    "To retrieve webpage data, we use the `requests` library. This function:\n",
    "- Takes a URL as input.\n",
    "- Sends a request to fetch the webpage.\n",
    "- Uses a user-agent header to mimic a real browser request.\n",
    "- Returns the HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bea461-af2a-4179-8c4c-024664c45c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_webpage(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}) # Header is included to mimic a browser, as some websites block automated requests if a user-agent header is missing\n",
    "        \n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        \n",
    "        return response.text # Returns the webpage's HTML content as a string using \"response.text\", which contains the entire webpage source in raw HTML format.\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching the webpage:\", e)\n",
    "        return None\n",
    "\n",
    "# Program initialization\n",
    "url = input(\"Enter a website URL: \")\n",
    "html_content = fetch_webpage(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a5db2-097a-4f24-9d30-ecf399d5201c",
   "metadata": {},
   "source": [
    "## Step 3: Extract Title and Content Using BeautifulSoup\n",
    "We now use `BeautifulSoup` to extract the webpage **title** and **main content** while removing unnecessary HTML elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db964eb-a059-4e8f-a38c-5973237bf332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ULKASEMI – We are integrating your ideas\n",
      "Content (first 500 characters): ULKASEMI – We are integrating your ideas Primary Menu Know More About Us Partnership Advantage News, Events And Gallery Legal Management Team Global Presence QMS Policy ISMS Policy Blog FAQs Our Clients Services Offerings Custom IC Design IC Design Services Circuit Design IC Design Verification Functional Verification AMS Verification Digital Verification PCB Design Physical Design SOC Design Foundry Design Services Software Software Development Software Reseller Industry served Career Contacts \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_content(html):\n",
    "    if not html:\n",
    "        return None, None\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract title\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "    # Extract text content while removing scripts and styles\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose()  # Remove script and style tags\n",
    "\n",
    "    content = ' '.join(soup.stripped_strings)  # Extract all text content while ignoring empty lines and removing extra spaces. ' '.join() joins all the extracted text into a single string , seperated by spaces.\n",
    "\n",
    "    return title, content\n",
    "\n",
    "# Example Usage (Only for test purpose)\n",
    "title, content = extract_content(html_content)\n",
    "print(\"Title:\", title)\n",
    "print(\"Content (first 500 characters):\", content[:500])  # Displaying only the first 500 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a499ca-34cd-4167-b021-27326760b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The webpage \"ULKASEMI – We are integrating your ideas\" appears to be a company website for ULKASEMI, a global leader in semiconductor design services. The content is structured into various sections:\n",
      "\n",
      "1. **About Us**: Introduces ULKASEMI as a 17-year-old company with expertise in semiconductor design services.\n",
      "2. **Services Offerings**: Lists the company's services, including custom IC design, circuit design, and verification, as well as software development and reseller services.\n",
      "3. **Partnership Advantage**: Highlights ULKASEMI's partnerships and collaborations with clients across various industries.\n",
      "4. **Global Presence**: Informally mentions that ULKASEMI has a global presence.\n",
      "\n",
      "The primary focus of the website seems to be promoting ULKASEMI's capabilities in semiconductor design services, emphasizing its expertise in areas such as custom IC design, physical design, verification, and software development.\n"
     ]
    }
   ],
   "source": [
    "## **Step 4: Use Llama 3.2 to Generate a Summary**\n",
    "\n",
    "import ollama\n",
    "\n",
    "def summarize_content(title, content):\n",
    "    prompt = f\"Here is a webpage titled '{title}'. Summarize its content briefly:\\n\\n{content[:2000]}\"  # Limit to 2000 characters\n",
    "    response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    \n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example Usage\n",
    "if title and content:\n",
    "    summary = summarize_content(title, content)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68db40b-ba69-4a21-9333-1f089772e327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
