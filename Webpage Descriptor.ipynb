{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4847715f-312a-4e7a-b662-b356794a4ce8",
   "metadata": {},
   "source": [
    "# LLM Project: Webpage Descriptor using Llama 3.2\n",
    "\n",
    "This program fetches content of a webpage via user-input and then will output the title of the webpage as well as a small summary of the page with the help of a LLM Model (Llama 3.2).\n",
    "\n",
    "## Step 1: Install Required Libraries\n",
    "To begin, we need the following Python libraries:\n",
    "- `requests`: To fetch the webpage content.\n",
    "- `beautifulsoup4`: To parse and clean up the webpage HTML.\n",
    "- `ollama`: To interface with the locally installed Llama 3.2 model.\n",
    "\n",
    "Once the libraries has been installed in your environment, open up a Jupyter notebook and proceed to next steps.\n",
    "\n",
    "## Step 2: Fetch Webpage Content\n",
    "To retrieve webpage data, we use the `requests` library. This function:\n",
    "- Takes a URL as input.\n",
    "- Sends a request to fetch the webpage.\n",
    "- Uses a user-agent header to mimic a real browser request.\n",
    "- Returns the HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02bea461-af2a-4179-8c4c-024664c45c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a website URL:  https://open.spotify.com/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_webpage(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}) # Header is included to mimic a browser, as some websites block automated requests if a user-agent header is missing\n",
    "        \n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        \n",
    "        return response.text # Returns the webpage's HTML content as a string using \"response.text\", which contains the entire webpage source in raw HTML format.\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching the webpage:\", e)\n",
    "        return None\n",
    "\n",
    "# Program initialization\n",
    "url = input(\"Enter a website URL: \")\n",
    "html_content = fetch_webpage(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a5db2-097a-4f24-9d30-ecf399d5201c",
   "metadata": {},
   "source": [
    "## Step 3: Extract Title and Content Using BeautifulSoup\n",
    "We now use `BeautifulSoup` to extract the webpage **title** and **main content** while removing unnecessary HTML elements.\n",
    "\n",
    "**Functionality:**\n",
    "- Extracts the `<title>` of the webpage.\n",
    "- Removes unnecessary elements like `<script>` and `<style>`.\n",
    "- Collects visible text into a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db964eb-a059-4e8f-a38c-5973237bf332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Spotify - Web Player: Music for everyone\n",
      "Content (first 500 characters): Spotify - Web Player: Music for everyone Popular artists Lady Gaga David Guetta Rihanna The Weeknd Eminem Billie Eilish Linkin Park Coldplay Apache 207 Taylor Swift Nina Chuba CRO Sido FiNCH Ed Sheeran Pitbull Beyoncé Kendrick Lamar Lost Frequencies AYLIVA Popular albums and singles DeBÍ TiRAR MáS FOToS HIT ME HARD AND SOFT Gesegnet Hurry Up Tomorrow Folge 231: und der Dreiäugige Schakal From Zero Regengeräusche zum Entspannung In Liebe GNX LID GOVA SABÍA QUE NO The Secret of Us (Deluxe) tau mic\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_content(html):\n",
    "    if not html:\n",
    "        return None, None\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract title\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "    # Extract text content while removing scripts and styles\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose()  # Remove script and style tags\n",
    "\n",
    "    content = ' '.join(soup.stripped_strings)  # Extract all text content while ignoring empty lines and removing extra spaces. ' '.join() joins all the extracted text into a single string , seperated by spaces.\n",
    "\n",
    "    return title, content\n",
    "\n",
    "# Example Usage (Only for test purpose)\n",
    "title, content = extract_content(html_content)\n",
    "print(\"Title:\", title)\n",
    "print(\"Content (first 500 characters):\", content[:500])  # Displaying only the first 500 chars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2eabe3-b691-4842-9523-44fda095f6b7",
   "metadata": {},
   "source": [
    "## Step 4: Use Llama 3.2 to Generate a Summary\n",
    "Now, we use the `ollama` library to process the webpage content using the locally installed **Llama 3.2** model.\n",
    "\n",
    "**Functionality:**\n",
    "- Sends the webpage title and extracted content (up to 2000 characters) to Llama 3.2.\n",
    "- Requests a short summary of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a499ca-34cd-4167-b021-27326760b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Website Title:\n",
      " Spotify - Web Player: Music for everyone\n",
      "\n",
      " About the website:\n",
      " The webpage 'Spotify - Web Player: Music for everyone' features a vast collection of popular music from various artists. It includes:\n",
      "\n",
      "* Popular artists such as Lady Gaga, David Guetta, Rihanna, The Weeknd, Eminem, and Billie Eilish\n",
      "* Albums and singles by multiple artists, including some in different languages (e.g., Spanish)\n",
      "* Soundtracks for TV shows and movies like Arcane and League of Legends\n",
      "* Radio stations dedicated to specific artists or genres\n",
      "\n",
      "Overall, the webpage showcases a diverse range of music from various artists and styles.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def summarize_content(title, content):\n",
    "    prompt = f\"Here is a webpage titled '{title}'. Summarize its content briefly:\\n\\n{content[:2000]}\"  # Limit to 2000 characters\n",
    "    response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    \n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "''' \"response\" is a dictionary (JSON-like structure) that is returned by ollama.chat(). \n",
    "    A typical response from an AI chat model looks like this:\n",
    "\n",
    "    {\n",
    "    \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"(Response by the AI model)\"}\n",
    "    }\n",
    "\n",
    "    By using response[\"message\"][\"content\"] we extract only the content of AI's response\n",
    "'''\n",
    "\n",
    "# Generating the summary of the webpage\n",
    "if title and content:\n",
    "    summary = summarize_content(title, content)\n",
    "    print(\" Website Title:\\n\",title)\n",
    "    print(\"\\n About the website:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de864b38-4989-4d3d-bb9e-e80613f8302e",
   "metadata": {},
   "source": [
    "## Step 4b: Use OpenAI to Generate a Summary\n",
    "To generate summary using OpenAI API key, use following cell block. Make sure you have `openai` library installed to environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28435759-da42-40de-ac9d-975b9734b622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling OpenAI API: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 434. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error: Unable to generate summary.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Load API key from environment variable (if set), otherwise ask for it\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or input(\"Enter your OpenAI API key: \").strip()\n",
    "\n",
    "# Set the API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "def summarize_content(title, content):\n",
    "    prompt = f\"Here is a webpage titled '{title}'. Summarize its content briefly:\\n\\n{content[:2000]}\"  # Limit content to 2000 chars\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",  # Use \"gpt-3.5-turbo\" if needed\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,  # Controls randomness (0 = deterministic, 0.7 = balanced, 1 = creative)\n",
    "            max_tokens=300  # Limits response length\n",
    "        )\n",
    "\n",
    "        # Extract the AI's response\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    except openai.OpenAIError as e:\n",
    "        print(\"Error calling OpenAI API:\", e)\n",
    "        return \"Error: Unable to generate summary.\"\n",
    "\n",
    "# Generating the summary of the webpage\n",
    "if title and content:\n",
    "    summary = summarize_content(title, content)\n",
    "    print(\" Website Title:\\n\",title)\n",
    "    print(\"\\n About the website:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed160314-bd2e-4695-a271-f4cb58072d16",
   "metadata": {},
   "source": [
    "## Step 4c: Use local model with local-API key to generate a summary\n",
    "To generate summary using a local model with locally hosted API-key, use following cell block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baa006ff-8b3b-475f-b37d-4f3eb8770182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your local API key for the model:  http://127.0.0.1:1234\n",
      "Enter the exact model name:  mistralrp-noromaid-nsfw-mistral-7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling local API: 'choices'\n",
      "Error: Unable to generate summary.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Loading the local API key for the LLM model\n",
    "local_api = input(\"Enter your local API key for the model: \").strip()\n",
    "model_name = input(\"Enter the exact model name: \")\n",
    "BASE_URL = local_api\n",
    "\n",
    "def summarize_content(title, content):\n",
    "    prompt = f\"Here is a webpage titled '{title}'. Summarize its content briefly:\\n\\n{content[:2000]}\"  # Limit content\n",
    "\n",
    "    # Define the API request payload\n",
    "    payload = {\n",
    "        \"model\": model_name,  \n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send the request to API\n",
    "        response = requests.post(f\"{BASE_URL}/chat/completions\", json=payload)\n",
    "\n",
    "        # Check if response is successful\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"]  # Extract the text\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return \"Error: Unable to generate summary.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error calling local API:\", e)\n",
    "        return \"Error: Unable to generate summary.\"\n",
    "\n",
    "# Example Usage\n",
    "if title and content:\n",
    "    summary = summarize_content(title, content)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c45e1-1da2-49c6-9d48-37e2eab721eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
